
* `users.csv` — **60,000** пользователей
* `sessions.csv` — **329,866** сессий
* `events.csv` — **248,942** события (deposit/purchase/bonus/redeem)
* `ab_tests.csv` — **27,128** участников A/B
* `schema.sql` — DDL (PostgreSQL-ish)
* `README.txt` — описание/допущения

---

## Упражнения на этот датасет

### A. SQL — базовые (разогрев)

1. Сколько регистраций по дням? (daily new users)
2. Топ-10 стран по числу пользователей.
3. DAU по дням (по `sessions`, уникальные user_id в день).
4. MAU по месяцам.
5. DAU/MAU (stickiness) по месяцам.
6. Средняя длительность сессии по игре (`session_end - session_start`).
7. Топ-5 игр по суммарной `sessions.revenue`.
8. Сколько событий каждого типа по дням? (`events.event_type`)
9. Сколько уникальных платящих пользователей (есть `deposit` или `purchase`) за весь период?
10. **“Последние 7 дней”**: найти пользователей, у кого **SUM(purchase amount) за последние 7 дней > 100**.

### B. SQL — средний уровень (кохорты, окна, воронки)

11. Для каждого пользователя найти **дату первого депозита** и **время до первого депозита** (в днях от регистрации).
12. **Конверсия в депозит**: доля пользователей, сделавших депозит в первые 7 дней после регистрации (по источникам `source`).
13. **Payer conversion** по дням: доля DAU, которые сделали `purchase` в тот же день.
14. **ARPPU** по месяцам (purchase amount / #платящих в месяц).
15. **ARPDAU** по дням (purchase amount / DAU).
16. Cohort retention: D1/D7/D30 по когорте регистрации (по `registration_date`).
17. Сегментация по RFM-лайту:

* Recency = дни с последней сессии
* Frequency = число сессий за 30 дней
* Monetary = сумма purchase за 30 дней

18. Воронка: `registration -> first_session -> first_purchase` (в процентах и медианное время между шагами).
19. Rolling 7d: 7-дневный rolling sum `sessions.revenue` по дням (на уровне всей платформы).
20. Rolling 7d по пользователю: 7-дневная сумма purchase amount по каждому user_id (оконка).

### C. SQL — продвинутый (ближе к собесу)

21. Найти “анома́льные дни” по revenue: дни, где revenue выше среднего на **3σ** (можно через daily агрегат + z-score).
22. Разложить revenue по источникам (`source`) и устройствам (`device`) — вклад в общий revenue и динамика.
23. LTV-30 (упрощённо): сумма `purchase amount` за первые 30 дней после регистрации по когортам.
24. “Кто отвалился”: пользователи с **0 сессий за последние 14 дней**, но были активны раньше (верни список + их last_session_date).
25. Оптимизация: взять любой тяжёлый запрос (например DAU/Retention) и прикинуть, **какие индексы** нужны и почему (по колонкам WHERE/JOIN/ORDER).

---

## Python / pandas упражнения

26. Приведи типы дат/времени, проверь пропуски, сделай базовый EDA (describe + распределения amounts).
27. Собери **daily KPI-таблицу**: `date, DAU, purchases_sum, deposits_sum, revenue_sum, ARPDAU`.
28. Построй графики:

* DAU по дням
* revenue по дням
* rolling 7d revenue (поверх)

29. Cohort retention в pandas (heatmap): когорты по неделям регистрации, retention по неделям жизни.
30. Посчитай по каждому user_id: `first_session_date`, `first_purchase_date`, `days_to_first_purchase`.
31. Сравни метрики по странам: DAU, ARPDAU, payer conversion (таблица + bar chart).
32. Построй “фанель” в pandas: registration → session → purchase (конверсия по источникам).

---

## Статистика / A/B (на этом же датасете)

В `ab_tests` есть тест `new_bonus_banner_v1` (A/B). В данных есть небольшой эффект для группы B после `test_start_date`.

33. **SRM-проверка**: доля A/B близка к 50/50? (χ² тест на соответствие сплиту)
34. Основная метрика: `purchase amount per user` за 14 дней после `test_start_date`. Сравни A vs B:

* среднее/медиана
* разница и % uplift

35. t-test (или bootstrap) для разницы средних, посчитать p-value.
36. Доверительный интервал для uplift (bootstrap 1000–5000 итераций).
37. Guardrail: не ухудшилась ли **retention D7** или **средняя длительность сессии** в группе B?
38. Сегментация эффекта: эффект A/B по `device` и `source` (где сильнее/слабее).
